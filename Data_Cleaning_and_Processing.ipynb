{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab413428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3e0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook raises warnings about the data types in a couple columns of the later data sets. These columns get dropped, \n",
    "# so the warnings aren't important. This suppresses the warnings as the code runs.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cea0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of raw data files. The structure of the files changes after January 2021, and need to be processed slightly differently.\n",
    "\n",
    "raw_data_early = [\"raw_data/201809-citibike-tripdata.csv\", \"raw_data/201810-citibike-tripdata.csv\", \"raw_data/201811-citibike-tripdata.csv\", \"raw_data/201812-citibike-tripdata.csv\", \"raw_data/201901-citibike-tripdata.csv\", \"raw_data/201902-citibike-tripdata.csv\", \"raw_data/201903-citibike-tripdata.csv\", \"raw_data/201904-citibike-tripdata.csv\", \"raw_data/201905-citibike-tripdata.csv\", \"raw_data/201906-citibike-tripdata.csv\", \"raw_data/201907-citibike-tripdata.csv\", \"raw_data/201908-citibike-tripdata.csv\", \"raw_data/201909-citibike-tripdata.csv\", \"raw_data/201910-citibike-tripdata.csv\", \"raw_data/201911-citibike-tripdata.csv\", \"raw_data/201912-citibike-tripdata.csv\", \"raw_data/202001-citibike-tripdata.csv\", \"raw_data/202002-citibike-tripdata.csv\", \"raw_data/202003-citibike-tripdata.csv\", \"raw_data/202004-citibike-tripdata.csv\", \"raw_data/202005-citibike-tripdata.csv\", \"raw_data/202006-citibike-tripdata.csv\", \"raw_data/202007-citibike-tripdata.csv\", \"raw_data/202008-citibike-tripdata.csv\", \"raw_data/202009-citibike-tripdata.csv\", \"raw_data/202010-citibike-tripdata.csv\", \"raw_data/202011-citibike-tripdata.csv\", \"raw_data/202012-citibike-tripdata.csv\", \"raw_data/202101-citibike-tripdata.csv\"]\n",
    "\n",
    "raw_data_later = [\"raw_data/202102-citibike-tripdata.csv\", \"raw_data/202103-citibike-tripdata.csv\", \"raw_data/202104-citibike-tripdata.csv\", \"raw_data/202105-citibike-tripdata.csv\", \"raw_data/202106-citibike-tripdata.csv\", \"raw_data/202107-citibike-tripdata.csv\", \"raw_data/202108-citibike-tripdata.csv\", \"raw_data/202109-citibike-tripdata.csv\", \"raw_data/202110-citibike-tripdata.csv\", \"raw_data/202111-citibike-tripdata.csv\", \"raw_data/202112-citibike-tripdata.csv\", \"raw_data/202201-citibike-tripdata.csv\", \"raw_data/202202-citibike-tripdata.csv\", \"raw_data/202203-citibike-tripdata.csv\", \"raw_data/202204-citibike-tripdata.csv\", \"raw_data/202205-citibike-tripdata.csv\", \"raw_data/202206-citibike-tripdata.csv\", \"raw_data/202207-citibike-tripdata.csv\", \"raw_data/202208-citibike-tripdata.csv\", \"raw_data/202209-citibike-tripdata.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb456bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function cleans the data from data files from February, 2021 and later.\n",
    "\n",
    "def clean_data_later(csv):\n",
    "    # Read the CSV into a dataframe\n",
    "    raw_data = pd.read_csv(csv)\n",
    "    # Drop the columns I'm not interested in\n",
    "    dropped_columns = raw_data.drop(columns=[\"ride_id\", \"start_station_id\", \"end_station_id\", \"rideable_type\"])\n",
    "    # Drop any entries with missing data\n",
    "    dropped_nas = dropped_columns.dropna()\n",
    "    # Drop any duplicated entries\n",
    "    dropped_dups = dropped_nas.drop_duplicates(ignore_index=True)\n",
    "    # Reindex the cleaned dataframe\n",
    "    reindexed_df = dropped_dups.reset_index(drop=True)\n",
    "    \n",
    "    return reindexed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd384b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is an adjusted version of my clean_data function. This function has the additional steps of masking the titles\n",
    "# of the columns to match the columns of the data files after January, 2021. This function is only used for data files from\n",
    "# January, 2021 and earlier.\n",
    "\n",
    "def clean_data_early(csv):\n",
    "    # Read the raw CSV into a dataframe\n",
    "    raw_data = pd.read_csv(csv)\n",
    "    # Mask the column titles so they match with the later data sets\n",
    "    masked_cols = raw_data.rename(columns = {\"tripduration\": \"ride_time\", \"starttime\": \"started_at\", \"stoptime\": \"ended_at\", \"start station id\": \"start_station_id\", \"start station name\": \"start_station_name\", \"start station latitude\": \"start_lat\", \"start station longitude\": \"start_lng\", \"end station id\": \"end_station_id\", \"end station name\": \"end_station_name\", \"end station latitude\": \"end_lat\", \"end station longitude\": \"end_lng\", \"usertype\":\"member_casual\"})\n",
    "    # Mask the values of the column to match later data sets\n",
    "    masked_cols[\"member_casual\"] = masked_cols[\"member_casual\"].map({\"Subscriber\": \"member\", \"Customer\": \"casual\"})\n",
    "    # Drop columns I'm not interested in\n",
    "    dropped_cols = masked_cols.drop(columns=[\"start_station_id\", \"end_station_id\", \"bikeid\", \"birth year\", \"gender\"])\n",
    "    # Rearrange the columns to match the later data sets\n",
    "    rearranged = dropped_cols[[\"started_at\", \"ended_at\", \"start_station_name\", \"start_lat\", \"start_lng\", \"end_station_name\", \"end_lat\", \"end_lng\", \"member_casual\", \"ride_time\"]]\n",
    "    # Drop any entries with incomplete data\n",
    "    dropped_nas = rearranged.dropna()\n",
    "    # Drop any duplicated entries\n",
    "    dropped_dups = dropped_nas.drop_duplicates(ignore_index = True)\n",
    "    # Reindex the dataframe\n",
    "    reindexed_df = dropped_dups.reset_index(drop = True)\n",
    "    \n",
    "    return reindexed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aeef0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a random sample of 5,000 entries for visualization with Tableau. This keeps the amount of data Tableau has to work \n",
    "# with to a more reasonable level, and it keeps the resulting CSV file under GitHub's maximum file size.\n",
    "def take_random_sample(df):\n",
    "    # Make a random list of 5,000 numbers from the range of indices\n",
    "    random_list = random.sample(range(0, len(df)), 5000)\n",
    "    # Use the list of random numbers to pull out entries with the corresponding index\n",
    "    sample_df = df[df.index.isin(random_list)]\n",
    "    # Reset the index\n",
    "    sample_df = sample_df.reset_index(drop=True)\n",
    "    \n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de64e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the geographic coordinates of each entry to 3 decimal points. This helps trips at the same stations to get grouped \n",
    "#together.\n",
    "\n",
    "def round_coords(df):\n",
    "    df[\"start_lat\"] = df[\"start_lat\"].round(3)\n",
    "    df[\"start_lng\"] = df[\"start_lng\"].round(3)\n",
    "    df[\"end_lat\"] = df[\"end_lat\"].round(3)\n",
    "    df[\"end_lng\"] = df[\"end_lng\"].round(3)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f93d20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This calculates how long each trip took in seconds and adds it to the dataframe. This is only needed for data *after*\n",
    "# January 2021.\n",
    "\n",
    "def calculate_ride_time(df):\n",
    "    ride_time = []\n",
    "\n",
    "    for event in range(0, len(df)):\n",
    "        # Convert started_at to datetime object, save it\n",
    "        started_dt = dt.datetime.strptime(df[\"started_at\"][event], \"%Y-%m-%d %H:%M:%S\")\n",
    "        # Convert ended_at to datetime object, save it\n",
    "        ended_dt = dt.datetime.strptime(df[\"ended_at\"][event], \"%Y-%m-%d %H:%M:%S\")\n",
    "        # Calculate elapsed time in seconds\n",
    "        time_change = ended_dt - started_dt\n",
    "        elapsed_seconds = time_change.seconds        \n",
    "        # Append string to series\n",
    "        ride_time.append(elapsed_seconds)\n",
    "        \n",
    "    df[\"ride_time\"] = ride_time\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d37c5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa7f285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_month_year(cleaned_data):\n",
    "    first_date = cleaned_data[\"started_at\"][0].split(\"-\")\n",
    "    month_year = first_date[1] + \"-\" + first_date[0]\n",
    "    return month_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b251c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_ridership(cleaned_data):\n",
    "    # Extract the month and year from the data\n",
    "    month_year = extract_month_year(cleaned_data)\n",
    "    # Count the number of riders in the full, cleaned data set\n",
    "    ridership = len(cleaned_data)\n",
    "    \n",
    "    ridership_dict.update({month_year: ridership})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0898ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_early(raw_data):\n",
    "    cleaned_data = clean_data_early(raw_data)\n",
    "    total_ridership(cleaned_data)\n",
    "    sample = take_random_sample(cleaned_data)\n",
    "    rounded_sample = round_coords(sample)\n",
    "    \n",
    "    return rounded_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcb2395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_later(raw_data):\n",
    "    cleaned_data = clean_data_later(raw_data)\n",
    "    sample = take_random_sample(cleaned_data)\n",
    "    total_ridership(cleaned_data)\n",
    "    rounded_sample = round_coords(sample)\n",
    "    with_ride_time = calculate_ride_time(rounded_sample)\n",
    "    \n",
    "    return with_ride_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac3b6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_early_samples_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54e4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d18f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc255bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in raw_data_early:\n",
    "    processed_month = process_early(month)\n",
    "    \n",
    "    processed_early_samples_df = pd.concat(objs = [processed_early_samples_df, processed_month])\n",
    "    processed_early_samples_df = processed_early_samples_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee723d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_later_samples_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c079838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in raw_data_later:\n",
    "    processed_later_month = process_later(month)\n",
    "    \n",
    "    processed_later_samples_df = pd.concat(objs = [processed_later_samples_df, processed_later_month])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1fdb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_total_samples_df = pd.concat(objs=[processed_early_samples_df, processed_later_samples_df])\n",
    "\n",
    "processed_total_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4407091",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_total_samples_df.to_csv(\"data_for_analysis/sep_18_to_sep_22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df = pd.DataFrame.from_dict(ridership_dict, orient=\"index\")\n",
    "\n",
    "ridership_df.columns = [\"Total_Rides\"]\n",
    "\n",
    "ridership_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df.to_csv(\"data_for_analysis/monthly_ridership.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a799e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
