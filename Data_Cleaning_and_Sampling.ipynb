{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e208a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb9d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook raises warnings about the data types in a couple columns of the later data sets. These columns get dropped, \n",
    "# so the warnings aren't important. This suppresses the warnings as the code runs.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f6748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of raw data files. The structure of the files changes after January 2021, and need to be processed slightly differently.\n",
    "\n",
    "raw_data_early = [\"raw_data/201809-citibike-tripdata.csv\", \"raw_data/201810-citibike-tripdata.csv\", \"raw_data/201811-citibike-tripdata.csv\", \"raw_data/201812-citibike-tripdata.csv\", \"raw_data/201901-citibike-tripdata.csv\", \"raw_data/201902-citibike-tripdata.csv\", \"raw_data/201903-citibike-tripdata.csv\", \"raw_data/201904-citibike-tripdata.csv\", \"raw_data/201905-citibike-tripdata.csv\", \"raw_data/201906-citibike-tripdata.csv\", \"raw_data/201907-citibike-tripdata.csv\", \"raw_data/201908-citibike-tripdata.csv\", \"raw_data/201909-citibike-tripdata.csv\", \"raw_data/201910-citibike-tripdata.csv\", \"raw_data/201911-citibike-tripdata.csv\", \"raw_data/201912-citibike-tripdata.csv\", \"raw_data/202001-citibike-tripdata.csv\", \"raw_data/202002-citibike-tripdata.csv\", \"raw_data/202003-citibike-tripdata.csv\", \"raw_data/202004-citibike-tripdata.csv\", \"raw_data/202005-citibike-tripdata.csv\", \"raw_data/202006-citibike-tripdata.csv\", \"raw_data/202007-citibike-tripdata.csv\", \"raw_data/202008-citibike-tripdata.csv\", \"raw_data/202009-citibike-tripdata.csv\", \"raw_data/202010-citibike-tripdata.csv\", \"raw_data/202011-citibike-tripdata.csv\", \"raw_data/202012-citibike-tripdata.csv\", \"raw_data/202101-citibike-tripdata.csv\"]\n",
    "\n",
    "raw_data_later = [\"raw_data/202102-citibike-tripdata.csv\", \"raw_data/202103-citibike-tripdata.csv\", \"raw_data/202104-citibike-tripdata.csv\", \"raw_data/202105-citibike-tripdata.csv\", \"raw_data/202106-citibike-tripdata.csv\", \"raw_data/202107-citibike-tripdata.csv\", \"raw_data/202108-citibike-tripdata.csv\", \"raw_data/202109-citibike-tripdata.csv\", \"raw_data/202110-citibike-tripdata.csv\", \"raw_data/202111-citibike-tripdata.csv\", \"raw_data/202112-citibike-tripdata.csv\", \"raw_data/202201-citibike-tripdata.csv\", \"raw_data/202202-citibike-tripdata.csv\", \"raw_data/202203-citibike-tripdata.csv\", \"raw_data/202204-citibike-tripdata.csv\", \"raw_data/202205-citibike-tripdata.csv\", \"raw_data/202206-citibike-tripdata.csv\", \"raw_data/202207-citibike-tripdata.csv\", \"raw_data/202208-citibike-tripdata.csv\", \"raw_data/202209-citibike-tripdata.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b172123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function cleans the data from data files from February, 2021 and later.\n",
    "\n",
    "def clean_data_later(sample):\n",
    "    # Drop the columns I'm not interested in\n",
    "    dropped_columns = sample.drop(columns=[\"ride_id\", \"start_station_id\", \"end_station_id\", \"rideable_type\"])\n",
    "    # Drop any entries with missing data\n",
    "    dropped_nas = dropped_columns.dropna()\n",
    "    # Drop any duplicated entries\n",
    "    dropped_dups = dropped_nas.drop_duplicates(ignore_index=True)\n",
    "    # Reindex the cleaned dataframe\n",
    "    reindexed_df = dropped_dups.reset_index(drop=True)\n",
    "    \n",
    "    return reindexed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666bd52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function has the additional steps of masking the titles of the columns to match the columns of the data files after \n",
    "# January, 2021. This function is only used for data files from January, 2021 and earlier.\n",
    "\n",
    "def clean_data_early(sample):\n",
    "    # Mask the column titles so they match with the later data sets\n",
    "    masked_cols = sample.rename(columns = {\"tripduration\": \"ride_time\", \"starttime\": \"started_at\", \"stoptime\": \"ended_at\", \"start station id\": \"start_station_id\", \"start station name\": \"start_station_name\", \"start station latitude\": \"start_lat\", \"start station longitude\": \"start_lng\", \"end station id\": \"end_station_id\", \"end station name\": \"end_station_name\", \"end station latitude\": \"end_lat\", \"end station longitude\": \"end_lng\", \"usertype\":\"member_casual\"})\n",
    "    # Mask the values of the column to match later data sets\n",
    "    masked_cols[\"member_casual\"] = masked_cols[\"member_casual\"].map({\"Subscriber\": \"member\", \"Customer\": \"casual\"})\n",
    "    # Drop columns I'm not interested in\n",
    "    dropped_cols = masked_cols.drop(columns=[\"start_station_id\", \"end_station_id\", \"bikeid\", \"birth year\", \"gender\"])\n",
    "    # Rearrange the columns to match the later data sets\n",
    "    rearranged = dropped_cols[[\"started_at\", \"ended_at\", \"start_station_name\", \"start_lat\", \"start_lng\", \"end_station_name\", \"end_lat\", \"end_lng\", \"member_casual\", \"ride_time\"]]\n",
    "    # Drop any entries with incomplete data\n",
    "    dropped_nas = rearranged.dropna()\n",
    "    # Drop any duplicated entries\n",
    "    dropped_dups = dropped_nas.drop_duplicates(ignore_index = True)\n",
    "    # Reindex the dataframe\n",
    "    reindexed_df = dropped_dups.reset_index(drop = True)\n",
    "    \n",
    "    return reindexed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb987653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a random sample of 5,000 entries for visualization with Tableau. This keeps the amount of data Tableau has to work \n",
    "# with to a more reasonable level, and it keeps the resulting CSV file under GitHub's maximum file size.\n",
    "\n",
    "def take_random_sample(df):\n",
    "    # Make a random list of 5,000 numbers from the range of indices\n",
    "    random_list = random.sample(range(0, len(df)), 5000)\n",
    "    # Use the list of random numbers to pull out entries with the corresponding index\n",
    "    sample_df = df[df.index.isin(random_list)]\n",
    "    # Reset the index\n",
    "    sample_df = sample_df.reset_index(drop=True)\n",
    "    \n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7891375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the geographic coordinates of each entry to 3 decimal points. This helps trips at the same stations to get grouped \n",
    "#together.\n",
    "\n",
    "def round_coords(df):\n",
    "    df[\"start_lat\"] = df[\"start_lat\"].round(3)\n",
    "    df[\"start_lng\"] = df[\"start_lng\"].round(3)\n",
    "    df[\"end_lat\"] = df[\"end_lat\"].round(3)\n",
    "    df[\"end_lng\"] = df[\"end_lng\"].round(3)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e7e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This extracts the month and year from the data set for sets before or including January 2021.\n",
    "\n",
    "def extract_month_year_early(raw_data):\n",
    "    first_date = raw_data[\"starttime\"][0].split(\"-\")\n",
    "    month_year = first_date[1] + \"-\" + first_date[0]\n",
    "    return month_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af44c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This extracts the month and year from the data set for sets on or after February 2021.\n",
    "\n",
    "def extract_month_year(cleaned_data):\n",
    "    first_date = cleaned_data[\"started_at\"][0].split(\"-\")\n",
    "    month_year = first_date[1] + \"-\" + first_date[0]\n",
    "    return month_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "500a2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This captures the total number of rides for each month.\n",
    "\n",
    "def total_ridership(raw_data):\n",
    "    ridership = len(raw_data)\n",
    "    \n",
    "    return ridership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ef19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes the early data sets (before and including January 2021).\n",
    "\n",
    "def process_early_better(csv_path):\n",
    "    # Read in csv\n",
    "    raw_data_df = pd.read_csv(csv_path)\n",
    "    # Take the sample\n",
    "    sample = take_random_sample(raw_data_df)\n",
    "    # Clean the data \n",
    "    cleaned_data = clean_data_early(sample)\n",
    "    # Round the latitudes and longitudes\n",
    "    rounded_data = round_coords(cleaned_data)\n",
    "    # Add month_year column\n",
    "    rounded_data.insert(loc = 10, column = \"month_year\", value = extract_month_year_early(raw_data_df))\n",
    "    # Add total_ridership column\n",
    "    rounded_data.insert(loc = 11, column = \"total_ridership\", value = total_ridership(raw_data_df))\n",
    "        \n",
    "    return rounded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fd78603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This calculates how long each trip took in seconds and adds it to the dataframe. This is only needed for data *after*\n",
    "# January 2021.\n",
    "\n",
    "def calculate_ride_time(df):\n",
    "    ride_time = []\n",
    "\n",
    "    for event in range(0, len(df)):\n",
    "        # Convert started_at to datetime object, save it\n",
    "        started_dt = dt.datetime.strptime(df[\"started_at\"][event], \"%Y-%m-%d %H:%M:%S\")\n",
    "        # Convert ended_at to datetime object, save it\n",
    "        ended_dt = dt.datetime.strptime(df[\"ended_at\"][event], \"%Y-%m-%d %H:%M:%S\")\n",
    "        # Calculate elapsed time in seconds\n",
    "        time_change = ended_dt - started_dt\n",
    "        elapsed_seconds = time_change.seconds        \n",
    "        # Append string to series\n",
    "        ride_time.append(elapsed_seconds)\n",
    "        \n",
    "    df[\"ride_time\"] = ride_time\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d09fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes the later data sets (February 2021 and later). \n",
    "\n",
    "def process_later_better(csv_path):\n",
    "    # Read in the CSV\n",
    "    raw_data_df = pd.read_csv(csv_path)\n",
    "    # Take the sample\n",
    "    sample = take_random_sample(raw_data_df)\n",
    "    # Clean the sample\n",
    "    cleaned_data = clean_data_later(sample)\n",
    "    # Round the latitudes and longitudes\n",
    "    rounded_data = round_coords(cleaned_data)\n",
    "    # Add ride_time column\n",
    "    with_ride_time = calculate_ride_time(rounded_data)\n",
    "    # Add month_year column\n",
    "    with_ride_time.insert(loc = 10, column = \"month_year\", value = extract_month_year(cleaned_data))\n",
    "    # Add total_ridership column\n",
    "    with_ride_time.insert(loc = 11, column = \"total_ridership\", value = total_ridership(raw_data_df))\n",
    "    \n",
    "    return with_ride_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80cbe6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an empty dataframe for the early processed samples.\n",
    "\n",
    "processed_early_samples_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e76042b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the early data sets.\n",
    "\n",
    "for month in raw_data_early:\n",
    "    processed_month = process_early_better(month)\n",
    "    \n",
    "    processed_early_samples_df = pd.concat(objs = [processed_early_samples_df, processed_month])\n",
    "    processed_early_samples_df = processed_early_samples_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "985364d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an empty dataframe for the later processed samples.\n",
    "\n",
    "processed_later_samples_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5ea5d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the later data sets.\n",
    "\n",
    "for month in raw_data_later:\n",
    "    processed_month = process_later_better(month)\n",
    "    processed_later_samples_df = pd.concat(objs = [processed_later_samples_df, processed_month])\n",
    "    processed_later_samples_df = processed_later_samples_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93bfc80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the data sets together to make one big data set.\n",
    "\n",
    "total_data_df = pd.concat(objs = [processed_early_samples_df, processed_later_samples_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30ed84fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the whole data set as a CSV.\n",
    "\n",
    "total_data_df.to_csv(\"data_for_analysis/sep_18_to_sep_22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb2a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
